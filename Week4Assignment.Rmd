---
title: "Practical Machine Learning - Assignment"
author: "Lalitha Hariharan"
date: "21 December 2018"
output: html_document
---

```{r, echo=FALSE}
knitr::opts_chunk$set(error = TRUE)
```

## Introduction

The goal of the project is to build a model to predict how well exercises are done rather than just how often they are done. For this, we will use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants, the data source for which is available in the links below: 

Training data:
[https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv]

Test data:
[https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv]

The data for this project come from this source: [http://groupware.les.inf.puc-rio.br/har]. If you use the document you create for this class for any purpose please cite them as they have been very generous in allowing their data to be used for this kind of assignment.

## Getting data and cleaning

FIrst we will load the necessary libraries and read the data

```{r}
# Load libraries
suppressWarnings(suppressMessages(library(caret)))
suppressWarnings(suppressMessages(library(rpart)))
suppressWarnings(suppressMessages(library(rpart.plot)))
suppressWarnings(suppressMessages(library(RColorBrewer)))
#library(RGtk2)
#library(rattle)
suppressWarnings(suppressMessages(library(randomForest)))
#suppressWarnings(suppressMessages(library(gbm)))

#Read data
dt_training <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"))
dt_testing  <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"))

# read initial dimensions
dim(dt_training)
dim(dt_testing)

```

Next we will clean the data by removing fields having NA values, fields which have near zero variance and fields that are non-numeric

```{r}
#Remove fields with NA values > 95%
naColumns <- sapply(dt_training, function(x) mean(is.na(x))) > 0.95

dt_training <- dt_training[,naColumns == FALSE]
dt_testing <- dt_testing[,naColumns == FALSE]

# Remove fields with near zero variance
nearZeroVariance <- nearZeroVar(dt_training)

dt_training <- dt_training[,-nearZeroVariance]
dt_testing <- dt_testing[,-nearZeroVariance]

# Remove non-numeric fields (columns 1:7 are non-numeric)
dt_training <- dt_training[,8:59]
dt_testing <- dt_testing[,8:59]

# read dimensions post cleaning
dim(dt_training)
dim(dt_testing)

```

## Data Partition into training and testing data

In order to estimate the out of sample error of our predictor, we will split our dt_training data into a training data set (60% of the total cases) and a testing data set (40% of the total cases.

```{r}
set.seed(12345)

inTrain <- createDataPartition(dt_training$classe, p=0.6, list=FALSE)
training <- dt_training[inTrain,]
testing <- dt_training[-inTrain,]

dim(training)
dim(testing)
```

## Building the model

Let us now build 2 models - (1) Decision Tree (2) Random Forest and compare the accuracy

## (1) Decision Tree Model

The Decision Tree model is built and then validated using the testing set

```{r}
modelDT <- rpart(classe ~ ., data = training, method="class")
rpart.plot(modelDT$finalModel, roundint=FALSE)

#fancyRpartPlot(modelDT)

#predicting with this model
set.seed(12345)

prediction <- predict(modelDT, testing, type = "class")
confusionMatrix(prediction, testing$classe)

```

## (2) Random Forest Model

The Random Forest model is built and then validated using the testing set

```{r}
set.seed(12345)
modelRF <- randomForest(classe ~ ., data = training, ntree = 1000)

prediction <- predict(modelRF, testing, type = "class")
confusionMatrix(prediction, testing$classe)

```

## Testing the 2 models on the Testing Data (pml_testing.csv)

Now, the 2 models are testing using the actual training set

(1) Decision Tree Model
```{r}
predictionDT <- predict(modelDT, dt_testing, type = "class")
predictionDT
```

(2) Random Forest Model

```{r}
predictionRF <- predict(modelRF, dt_testing, type = "class")
predictionRF

```

## Conclusion
The above statistical data suggests that the Random Forest model has more accuracy (99%) than Decision Tree model (70%). Hence we will use the Random Forest model for final prediction of the test data for the quiz .

## Prediction of the testing data

```{r}
finalPrediction <- predict(modelRF, dt_testing )
finalPrediction
```
